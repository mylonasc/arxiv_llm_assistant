<html><head></head><html><head><style>
/* Style the button that is used to open and close the collapsible content */
.collapsible {
  background-color: #eee;
  color: #444;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
  font-size: 15px;
}

/* Add a background color to the button if it is clicked on (add the .active class with JS), and when you move the mouse over it (hover) */
.active, .collapsible:hover {
  background-color: #ccc;
}

/* Style the collapsible content. Note: hidden by default */
.content {
  padding: 0 18px;
  border: 5px ;
  margin: auto;
  width: 50%;
  padding: 10px;
}
</style></head><body><div class="intro content">
<h1>Unlocking the Potential of Large Language Models for Lasting Impact in Academic Research</h1>

<p>Large language models (LLMs) have the potential to revolutionize information retrieval (IR) systems and create a lasting impact in academic research. This survey provides an overview of the use of LLMs in query rewriters, retrievers, rerankers, and readers, and explores promising directions for future research. Recent research has introduced a new method, InstructGLM, which uses natural language instructions to enable large language models to perform graph learning tasks. This method has been tested on three datasets and has outperformed all competitive GNN baselines. Platypus is a family of fine-tuned and merged LLMs that achieves the highest performance on the HuggingFace Open LLM Leaderboard. It is trained on a curated dataset, Open-Platypus, which is released to the public. Platypus is computationally efficient, requiring only a single A100 GPU and 25k questions to train a 13B model in 5 hours. Additionally, a novel approach to defending against adversarial attacks on large language models (LLMs) has been proposed. By having the LLM self-examine its own responses, </div><div class="content">
<h4><a href=http://arxiv.org/abs/2308.07107v1>Large Language Models for Information Retrieval: A Survey (2308.07107v1)</a> </h4>
<p>
This survey provides an overview of the potential of large language models (LLMs) to revolutionize information retrieval (IR) systems. It covers the use of LLMs in query rewriters, retrievers, rerankers, and readers, and explores promising directions for future research. The potential benefits of LLMs for IR systems could have a lasting impact on academic research.</p>
</div>
<div class="content">
<h4><a href=http://arxiv.org/abs/2308.07134v1>Natural Language is All a Graph Needs (2308.07134v1)</a> </h4>
<p>
This paper presents a new method, InstructGLM, which uses natural language instructions to enable large language models to perform graph learning tasks. The method has been tested on three datasets and has outperformed all competitive GNN baselines, demonstrating the potential for lasting impact in academic research of the described techniques.</p>
</div>
<div class="content">
<h4><a href=http://arxiv.org/abs/2308.07317v1>Platypus: Quick, Cheap, and Powerful Refinement of LLMs (2308.07317v1)</a> </h4>
<p>
Platypus is a family of fine-tuned and merged Large Language Models (LLMs) that achieves the highest performance on the HuggingFace Open LLM Leaderboard. It is trained on a curated dataset, Open-Platypus, which is released to the public. Platypus is computationally efficient, requiring only a single A100 GPU and 25k questions to train a 13B model in 5 hours. This has the potential to create a lasting impact in academic research of LLMs, by providing a powerful and efficient technique for refinement.</p>
</div>
<div class="content">
<h4><a href=http://arxiv.org/abs/2308.07308v1>LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked (2308.07308v1)</a> </h4>
<p>
This paper presents a novel approach to defending against adversarial attacks on large language models (LLMs). By having the LLM self-examine its own responses, it can detect and prevent the generation of harmful content. This technique has the potential to create a lasting impact in academic research, as it provides a simple and effective way to protect users from malicious content.</p>
</div>
<div class="content">
<h4><a href=http://arxiv.org/abs/2308.07282v1>Comparison between parameter-efficient techniques and full fine-tuning: A case study on multilingual news article classification (2308.07282v1)</a> </h4>
<p>
This paper investigates the potential of parameter-efficient fine-tuning techniques to improve performance and reduce computation costs in multilingual text classification tasks. Results suggest that these techniques can have a lasting impact in academic research, providing valuable insights into their applicability to complex tasks.</p>
</div>
<div class="content">
<h4><a href=http://arxiv.org/abs/2308.07037v1>Bayesian Flow Networks (2308.07037v1)</a> </h4>
<p>
This paper introduces Bayesian Flow Networks (BFNs), a new generative model that combines Bayesian inference and neural networks to create interdependent distributions. BFNs have the potential to create a lasting impact in academic research by providing a simpler conceptually process than diffusion models, natively differentiable network inputs, and competitive log-likelihoods for image modelling.</p>
</div>
<div class="content">
<h4><a href=http://arxiv.org/abs/2308.07305v1>Neural Authorship Attribution: Stylometric Analysis on Large Language Models (2308.07305v1)</a> </h4>
<p>
This paper explores the potential of neural authorship attribution to trace AI-generated text back to its originating LLM. Through an empirical analysis of LLM writing signatures, the authors highlight the contrasts between proprietary and open-source models and their potential to yield interpretable results. The findings of this work could have a lasting impact in academic research, providing insights into neural authorship attribution and mitigating the threats posed by AI-generated misinformation.</p>
</div>
<div class="content">
<h4><a href=http://arxiv.org/abs/2308.07120v1>Mind your Language (Model): Fact-Checking LLMs and their Role in NLP Research and Practice (2308.07120v1)</a> </h4>
<p>
This paper provides a definition of LLMs and examines the assumptions made about their functionality, with the potential to create a lasting impact in academic research and practice. It offers evidence for and against LLMs, and suggests research directions for future work.</p>
</div>
<div class="content">
<h4><a href=http://arxiv.org/abs/2308.07201v1>ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate (2308.07201v1)</a> </h4>
<p>
ChatEval is a multi-agent debate framework that uses LLMs to evaluate the quality of generated responses from different models. It offers a human-mimicking evaluation process that has the potential to create a lasting impact in academic research, by providing a reliable and efficient alternative to manual evaluation.</p>
</div>
<div class="content">
<h4><a href=http://arxiv.org/abs/2308.07110v1>SCSC: Spatial Cross-scale Convolution Module to Strengthen both CNNs and Transformers (2308.07110v1)</a> </h4>
<p>
This paper presents a module, SCSC, which can improve both CNNs and Transformers, leading to better performance in face recognition and ImageNet classification tasks. SCSC introduces an efficient spatial cross-scale encoder and spatial embed module to capture assorted features in one layer, resulting in fewer FLOPs and parameters. The potential for the presented benefits to create a lasting impact in academic research of the described techniques is high.</p>
</div></body></html><body></body></html>